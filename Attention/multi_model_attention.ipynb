{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "import numpy as np\n",
    "from keras import Model\n",
    "from keras.layers import Layer\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Dense, SimpleRNN,LSTM,Bidirectional\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Dataset\n",
    "The following function generates a sequence of n Fibonacci numbers (not counting the starting two values). If scale_data is set to True, then it would also use the MinMaxScaler from scikit-learn to scale the values between 0 and 1. Letâ€™s see its output for n=10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "def get_fib_seq(n, scale_data=True):\n",
    "    # Get the Fibonacci sequence\n",
    "    seq = np.zeros(n)\n",
    "    fib_n1 = 0.0\n",
    "    fib_n = 1.0 \n",
    "    for i in range(n):\n",
    "            seq[i] = fib_n1 + fib_n\n",
    "            fib_n1 = fib_n\n",
    "            fib_n = seq[i] \n",
    "    scaler = []\n",
    "    if scale_data:\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        seq = np.reshape(seq, (n, 1))\n",
    "        seq = scaler.fit_transform(seq).flatten()        \n",
    "    return seq, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  2.  3.  5.  8. 13. 21. 34. 55. 89.]\n"
     ]
    }
   ],
   "source": [
    "fib_seq = get_fib_seq(10, False)[0]\n",
    "print(fib_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Function get_fib_XY() that reformats the sequence into training examples and target values to be used by the Keras input layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Time_steps is number of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fib_XY(total_fib_numbers, time_steps, train_percent, scale_data=True):\n",
    "    dat, scaler = get_fib_seq(total_fib_numbers, scale_data)    \n",
    "    Y_ind = np.arange(time_steps, len(dat), 1)\n",
    "    Y = dat[Y_ind]\n",
    "    rows_x = len(Y)\n",
    "    X = dat[0:rows_x]\n",
    "    for i in range(time_steps-1):\n",
    "        temp = dat[i+1:rows_x+i+1]\n",
    "        X = np.column_stack((X, temp))\n",
    "    # random permutation with fixed seed   \n",
    "    rand = np.random.RandomState(seed=13)\n",
    "    idx = rand.permutation(rows_x)\n",
    "    split = int(train_percent*rows_x)\n",
    "    train_ind = idx[0:split]\n",
    "    test_ind = idx[split:]\n",
    "    trainX = X[train_ind]\n",
    "    trainY = Y[train_ind]\n",
    "    testX = X[test_ind]\n",
    "    testY = Y[test_ind]\n",
    "    trainX = np.reshape(trainX, (len(trainX), time_steps, 1))    \n",
    "    testX = np.reshape(testX, (len(testX), time_steps, 1))\n",
    "    return trainX, trainY, testX, testY, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up parameters\n",
    "time_steps = 20\n",
    "hidden_units = 2\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "performance = pd.DataFrame({\"model\":[] ,'Train_set_MSE':[],'Test_set_MSE':[]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\veera\\anaconda3\\envs\\DEV\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\veera\\anaconda3\\envs\\DEV\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a traditional RNN network\n",
    "def create_simple_RNN(hidden_units, dense_units, input_shape, activation):\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(hidden_units, input_shape=input_shape, activation=activation[0]))\n",
    "    model.add(Dense(units=dense_units, activation=activation[1]))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "model_RNN = create_simple_RNN(hidden_units=hidden_units, dense_units=1, input_shape=(time_steps,1), \n",
    "                   activation=['tanh', 'tanh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:From c:\\Users\\veera\\anaconda3\\envs\\DEV\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "826/826 - 3s - loss: 0.0031 - 3s/epoch - 4ms/step\n",
      "Epoch 2/30\n",
      "826/826 - 2s - loss: 0.0028 - 2s/epoch - 3ms/step\n",
      "Epoch 3/30\n",
      "826/826 - 2s - loss: 0.0026 - 2s/epoch - 3ms/step\n",
      "Epoch 4/30\n",
      "826/826 - 2s - loss: 0.0024 - 2s/epoch - 3ms/step\n",
      "Epoch 5/30\n",
      "826/826 - 2s - loss: 0.0022 - 2s/epoch - 3ms/step\n",
      "Epoch 6/30\n",
      "826/826 - 2s - loss: 0.0020 - 2s/epoch - 3ms/step\n",
      "Epoch 7/30\n",
      "826/826 - 2s - loss: 0.0018 - 2s/epoch - 3ms/step\n",
      "Epoch 8/30\n",
      "826/826 - 2s - loss: 0.0016 - 2s/epoch - 3ms/step\n",
      "Epoch 9/30\n",
      "826/826 - 2s - loss: 0.0015 - 2s/epoch - 3ms/step\n",
      "Epoch 10/30\n",
      "826/826 - 2s - loss: 0.0013 - 2s/epoch - 3ms/step\n",
      "Epoch 11/30\n",
      "826/826 - 2s - loss: 0.0012 - 2s/epoch - 3ms/step\n",
      "Epoch 12/30\n",
      "826/826 - 2s - loss: 0.0011 - 2s/epoch - 3ms/step\n",
      "Epoch 13/30\n",
      "826/826 - 2s - loss: 0.0010 - 2s/epoch - 3ms/step\n",
      "Epoch 14/30\n",
      "826/826 - 2s - loss: 9.1181e-04 - 2s/epoch - 3ms/step\n",
      "Epoch 15/30\n",
      "826/826 - 2s - loss: 8.0716e-04 - 2s/epoch - 3ms/step\n",
      "Epoch 16/30\n",
      "826/826 - 2s - loss: 7.2742e-04 - 2s/epoch - 3ms/step\n",
      "Epoch 17/30\n",
      "826/826 - 2s - loss: 6.4012e-04 - 2s/epoch - 3ms/step\n",
      "Epoch 18/30\n",
      "826/826 - 2s - loss: 5.4765e-04 - 2s/epoch - 3ms/step\n",
      "Epoch 19/30\n",
      "826/826 - 2s - loss: 4.6643e-04 - 2s/epoch - 3ms/step\n",
      "Epoch 20/30\n",
      "826/826 - 2s - loss: 3.9822e-04 - 2s/epoch - 3ms/step\n",
      "Epoch 21/30\n",
      "826/826 - 2s - loss: 3.2572e-04 - 2s/epoch - 3ms/step\n",
      "Epoch 22/30\n",
      "826/826 - 2s - loss: 2.5724e-04 - 2s/epoch - 3ms/step\n",
      "Epoch 23/30\n",
      "826/826 - 2s - loss: 1.9683e-04 - 2s/epoch - 3ms/step\n",
      "Epoch 24/30\n",
      "826/826 - 2s - loss: 1.5170e-04 - 2s/epoch - 3ms/step\n",
      "Epoch 25/30\n",
      "826/826 - 2s - loss: 1.1853e-04 - 2s/epoch - 3ms/step\n",
      "Epoch 26/30\n",
      "826/826 - 2s - loss: 9.8107e-05 - 2s/epoch - 3ms/step\n",
      "Epoch 27/30\n",
      "826/826 - 2s - loss: 8.9873e-05 - 2s/epoch - 3ms/step\n",
      "Epoch 28/30\n",
      "826/826 - 2s - loss: 9.0133e-05 - 2s/epoch - 3ms/step\n",
      "Epoch 29/30\n",
      "826/826 - 2s - loss: 8.6655e-05 - 2s/epoch - 3ms/step\n",
      "Epoch 30/30\n",
      "826/826 - 2s - loss: 8.2903e-05 - 2s/epoch - 3ms/step\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 6.5481e-05\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.9172e-05\n",
      "Train set MSE = 0.0000655\n",
      "Test set MSE = 0.0000292\n"
     ]
    }
   ],
   "source": [
    "# Generate the dataset for the network\n",
    "trainX, trainY, testX, testY, scaler  = get_fib_XY(1200, time_steps, 0.7)\n",
    "# Train the network\n",
    "model_RNN.fit(trainX, trainY, epochs=epochs, batch_size=1, verbose=2)\n",
    "\n",
    "\n",
    "# Evalute model\n",
    "train_mse = model_RNN.evaluate(trainX, trainY)\n",
    "test_mse = model_RNN.evaluate(testX, testY)\n",
    "\n",
    "# Print error\n",
    "print(f\"Train set MSE = {train_mse:.{7}f}\")\n",
    "print(f\"Test set MSE = {test_mse:.{7}f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Train_set_MSE</th>\n",
       "      <th>Test_set_MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simple RNN</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model  Train_set_MSE  Test_set_MSE\n",
       "0  Simple RNN       0.000065      0.000029"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance = pd.concat([performance, pd.DataFrame({'model':'Simple RNN','Train_set_MSE':train_mse,'Test_set_MSE':test_mse},index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add attention layer to the deep learning network\n",
    "class attention(Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(attention,self).__init__(**kwargs)\n",
    "\n",
    "    def build(self,input_shape): #weights are automatically tuned\n",
    "        self.W=self.add_weight(name='attention_weight', shape=(input_shape[-1],1), \n",
    "                               initializer='random_normal', trainable=True)\n",
    "        self.b=self.add_weight(name='attention_bias', shape=(input_shape[1],1), \n",
    "                               initializer='zeros', trainable=True)        \n",
    "        super(attention, self).build(input_shape)\n",
    "\n",
    "    def call(self,x): # forward pass\n",
    "        # Alignment scores. Pass them through tanh function\n",
    "        e = K.tanh(K.dot(x,self.W)+self.b)\n",
    "        # Remove dimension of size 1\n",
    "        e = K.squeeze(e, axis=-1)   \n",
    "        # Compute the weights\n",
    "        alpha = K.softmax(e) # 0 to 1 - normalization\n",
    "        # Reshape to tensorFlow format\n",
    "        alpha = K.expand_dims(alpha, axis=-1)\n",
    "        # Compute the context vector\n",
    "        context = x * alpha\n",
    "        context = K.sum(context, axis=1)\n",
    "        return context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple RNN with Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 20, 1)]           0         \n",
      "                                                                 \n",
      " simple_rnn_1 (SimpleRNN)    (None, 20, 2)             8         \n",
      "                                                                 \n",
      " attention (attention)       (None, 2)                 22        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33 (132.00 Byte)\n",
      "Trainable params: 33 (132.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "826/826 - 4s - loss: 0.0017 - 4s/epoch - 5ms/step\n",
      "Epoch 2/30\n",
      "826/826 - 2s - loss: 0.0017 - 2s/epoch - 3ms/step\n",
      "Epoch 3/30\n",
      "826/826 - 2s - loss: 0.0017 - 2s/epoch - 3ms/step\n",
      "Epoch 4/30\n",
      "826/826 - 2s - loss: 0.0016 - 2s/epoch - 3ms/step\n",
      "Epoch 5/30\n",
      "826/826 - 2s - loss: 0.0016 - 2s/epoch - 3ms/step\n",
      "Epoch 6/30\n",
      "826/826 - 2s - loss: 0.0016 - 2s/epoch - 3ms/step\n",
      "Epoch 7/30\n",
      "826/826 - 2s - loss: 0.0016 - 2s/epoch - 3ms/step\n",
      "Epoch 8/30\n",
      "826/826 - 2s - loss: 0.0015 - 2s/epoch - 3ms/step\n",
      "Epoch 9/30\n",
      "826/826 - 2s - loss: 0.0015 - 2s/epoch - 3ms/step\n",
      "Epoch 10/30\n",
      "826/826 - 2s - loss: 0.0015 - 2s/epoch - 3ms/step\n",
      "Epoch 11/30\n",
      "826/826 - 2s - loss: 0.0015 - 2s/epoch - 3ms/step\n",
      "Epoch 12/30\n",
      "826/826 - 2s - loss: 0.0015 - 2s/epoch - 3ms/step\n",
      "Epoch 13/30\n",
      "826/826 - 2s - loss: 0.0015 - 2s/epoch - 3ms/step\n",
      "Epoch 14/30\n",
      "826/826 - 2s - loss: 0.0015 - 2s/epoch - 3ms/step\n",
      "Epoch 15/30\n",
      "826/826 - 2s - loss: 0.0014 - 2s/epoch - 3ms/step\n",
      "Epoch 16/30\n",
      "826/826 - 2s - loss: 0.0014 - 2s/epoch - 3ms/step\n",
      "Epoch 17/30\n",
      "826/826 - 2s - loss: 0.0014 - 2s/epoch - 3ms/step\n",
      "Epoch 18/30\n",
      "826/826 - 2s - loss: 0.0014 - 2s/epoch - 3ms/step\n",
      "Epoch 19/30\n",
      "826/826 - 2s - loss: 0.0014 - 2s/epoch - 3ms/step\n",
      "Epoch 20/30\n",
      "826/826 - 2s - loss: 0.0014 - 2s/epoch - 3ms/step\n",
      "Epoch 21/30\n",
      "826/826 - 2s - loss: 0.0013 - 2s/epoch - 3ms/step\n",
      "Epoch 22/30\n",
      "826/826 - 2s - loss: 0.0013 - 2s/epoch - 3ms/step\n",
      "Epoch 23/30\n",
      "826/826 - 2s - loss: 0.0013 - 2s/epoch - 3ms/step\n",
      "Epoch 24/30\n",
      "826/826 - 2s - loss: 0.0013 - 2s/epoch - 3ms/step\n",
      "Epoch 25/30\n",
      "826/826 - 2s - loss: 0.0012 - 2s/epoch - 3ms/step\n",
      "Epoch 26/30\n",
      "826/826 - 2s - loss: 0.0012 - 2s/epoch - 3ms/step\n",
      "Epoch 27/30\n",
      "826/826 - 2s - loss: 0.0011 - 2s/epoch - 3ms/step\n",
      "Epoch 28/30\n",
      "826/826 - 2s - loss: 0.0011 - 2s/epoch - 3ms/step\n",
      "Epoch 29/30\n",
      "826/826 - 2s - loss: 0.0010 - 2s/epoch - 3ms/step\n",
      "Epoch 30/30\n",
      "826/826 - 2s - loss: 0.0010 - 2s/epoch - 3ms/step\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 9.2867e-04\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.1279e-04\n",
      "Train set MSE = 0.0009287\n",
      "Test set MSE = 0.0008128\n"
     ]
    }
   ],
   "source": [
    "def create_RNN_with_attention(hidden_units, dense_units, input_shape, activation):\n",
    "    x=Input(shape=input_shape)\n",
    "    RNN_layer = SimpleRNN(hidden_units, return_sequences=True, activation=activation)(x)\n",
    "    attention_layer = attention()(RNN_layer)\n",
    "    outputs=Dense(dense_units, trainable=True, activation=activation)(attention_layer)\n",
    "    model=Model(x,outputs)\n",
    "    model.compile(loss='mse', optimizer='adam')    \n",
    "    return model    \n",
    "\n",
    "# Create the model with attention, train and evaluate\n",
    "model_attention = create_RNN_with_attention(hidden_units=hidden_units, dense_units=1, \n",
    "                                  input_shape=(time_steps,1), activation='tanh')\n",
    "model_attention.summary()    \n",
    "\n",
    "\n",
    "model_attention.fit(trainX, trainY, epochs=epochs, batch_size=1, verbose=2)\n",
    "\n",
    "# Evalute model\n",
    "train_mse = model_attention.evaluate(trainX, trainY)\n",
    "test_mse = model_attention.evaluate(testX, testY)\n",
    "\n",
    "# Print error\n",
    "print(f\"Train set MSE = {train_mse:.{7}f}\")\n",
    "print(f\"Test set MSE = {test_mse:.{7}f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Train_set_MSE</th>\n",
       "      <th>Test_set_MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simple RNN</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simple RNN with Attention</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>0.000813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model  Train_set_MSE  Test_set_MSE\n",
       "0                 Simple RNN       0.000065      0.000029\n",
       "0  Simple RNN with Attention       0.000929      0.000813"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance = pd.concat([performance, pd.DataFrame({'model':'Simple RNN with Attention','Train_set_MSE':train_mse,'Test_set_MSE':test_mse},index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_LSTM(hidden_units, dense_units, input_shape, activation):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(hidden_units, input_shape=input_shape, activation=activation[0]))\n",
    "    model.add(Dense(units=dense_units, activation=activation[1]))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "model_LSTM = create_LSTM(hidden_units=hidden_units, dense_units=1, input_shape=(time_steps,1), \n",
    "                   activation=['tanh', 'tanh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 2)                 32        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 35 (140.00 Byte)\n",
      "Trainable params: 35 (140.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "826/826 - 7s - loss: 0.0014 - 7s/epoch - 8ms/step\n",
      "Epoch 2/30\n",
      "826/826 - 3s - loss: 0.0014 - 3s/epoch - 4ms/step\n",
      "Epoch 3/30\n",
      "826/826 - 3s - loss: 0.0013 - 3s/epoch - 4ms/step\n",
      "Epoch 4/30\n",
      "826/826 - 3s - loss: 0.0013 - 3s/epoch - 4ms/step\n",
      "Epoch 5/30\n",
      "826/826 - 3s - loss: 0.0012 - 3s/epoch - 4ms/step\n",
      "Epoch 6/30\n",
      "826/826 - 3s - loss: 0.0012 - 3s/epoch - 4ms/step\n",
      "Epoch 7/30\n",
      "826/826 - 3s - loss: 0.0011 - 3s/epoch - 4ms/step\n",
      "Epoch 8/30\n",
      "826/826 - 4s - loss: 9.9450e-04 - 4s/epoch - 4ms/step\n",
      "Epoch 9/30\n",
      "826/826 - 3s - loss: 8.9650e-04 - 3s/epoch - 4ms/step\n",
      "Epoch 10/30\n",
      "826/826 - 3s - loss: 7.8078e-04 - 3s/epoch - 4ms/step\n",
      "Epoch 11/30\n",
      "826/826 - 4s - loss: 6.6082e-04 - 4s/epoch - 5ms/step\n",
      "Epoch 12/30\n",
      "826/826 - 4s - loss: 5.5505e-04 - 4s/epoch - 5ms/step\n",
      "Epoch 13/30\n",
      "826/826 - 3s - loss: 4.4702e-04 - 3s/epoch - 4ms/step\n",
      "Epoch 14/30\n",
      "826/826 - 3s - loss: 3.5563e-04 - 3s/epoch - 4ms/step\n",
      "Epoch 15/30\n",
      "826/826 - 3s - loss: 2.6218e-04 - 3s/epoch - 4ms/step\n",
      "Epoch 16/30\n",
      "826/826 - 3s - loss: 2.0268e-04 - 3s/epoch - 4ms/step\n",
      "Epoch 17/30\n",
      "826/826 - 3s - loss: 1.5283e-04 - 3s/epoch - 4ms/step\n",
      "Epoch 18/30\n",
      "826/826 - 3s - loss: 1.1108e-04 - 3s/epoch - 4ms/step\n",
      "Epoch 19/30\n",
      "826/826 - 3s - loss: 7.9665e-05 - 3s/epoch - 4ms/step\n",
      "Epoch 20/30\n",
      "826/826 - 3s - loss: 6.7595e-05 - 3s/epoch - 4ms/step\n",
      "Epoch 21/30\n",
      "826/826 - 3s - loss: 5.7071e-05 - 3s/epoch - 4ms/step\n",
      "Epoch 22/30\n",
      "826/826 - 3s - loss: 5.5998e-05 - 3s/epoch - 4ms/step\n",
      "Epoch 23/30\n",
      "826/826 - 3s - loss: 5.1519e-05 - 3s/epoch - 4ms/step\n",
      "Epoch 24/30\n",
      "826/826 - 3s - loss: 5.2450e-05 - 3s/epoch - 4ms/step\n",
      "Epoch 25/30\n",
      "826/826 - 3s - loss: 5.4531e-05 - 3s/epoch - 4ms/step\n",
      "Epoch 26/30\n",
      "826/826 - 3s - loss: 5.0011e-05 - 3s/epoch - 4ms/step\n",
      "Epoch 27/30\n",
      "826/826 - 3s - loss: 5.1648e-05 - 3s/epoch - 4ms/step\n",
      "Epoch 28/30\n",
      "826/826 - 3s - loss: 4.5443e-05 - 3s/epoch - 4ms/step\n",
      "Epoch 29/30\n",
      "826/826 - 3s - loss: 4.5564e-05 - 3s/epoch - 4ms/step\n",
      "Epoch 30/30\n",
      "826/826 - 3s - loss: 4.5163e-05 - 3s/epoch - 4ms/step\n",
      "26/26 [==============================] - 1s 3ms/step - loss: 3.0832e-05\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.0268e-05\n",
      "Train set MSE = 0.0000308\n",
      "Test set MSE = 0.0000103\n"
     ]
    }
   ],
   "source": [
    "model_LSTM.summary()    \n",
    "\n",
    "\n",
    "model_LSTM.fit(trainX, trainY, epochs=epochs, batch_size=1, verbose=2)\n",
    "\n",
    "# Evalute model\n",
    "train_mse = model_LSTM.evaluate(trainX, trainY)\n",
    "test_mse = model_LSTM.evaluate(testX, testY)\n",
    "\n",
    "# Print error\n",
    "print(f\"Train set MSE = {train_mse:.{7}f}\")\n",
    "print(f\"Test set MSE = {test_mse:.{7}f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Train_set_MSE</th>\n",
       "      <th>Test_set_MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simple RNN</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simple RNN with Attention</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>0.000813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model  Train_set_MSE  Test_set_MSE\n",
       "0                 Simple RNN       0.000065      0.000029\n",
       "0  Simple RNN with Attention       0.000929      0.000813\n",
       "0                       LSTM       0.000031      0.000010"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance = pd.concat([performance, pd.DataFrame({'model':'LSTM','Train_set_MSE':train_mse,'Test_set_MSE':test_mse},index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM with Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 20, 1)]           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 20, 2)             32        \n",
      "                                                                 \n",
      " attention_1 (attention)     (None, 2)                 22        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57 (228.00 Byte)\n",
      "Trainable params: 57 (228.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_LSTM_with_attention(hidden_units, dense_units, input_shape, activation):\n",
    "    x=Input(shape=input_shape)\n",
    "    LSTM_layer = LSTM(hidden_units, return_sequences=True, activation=activation)(x)\n",
    "    attention_layer = attention()(LSTM_layer)\n",
    "    outputs=Dense(dense_units, trainable=True, activation=activation)(attention_layer)\n",
    "    model=Model(x,outputs)\n",
    "    model.compile(loss='mse', optimizer='adam')    \n",
    "    return model    \n",
    "\n",
    "# Create the model with attention, train and evaluate\n",
    "model_LSTM_with_attention = create_LSTM_with_attention(hidden_units=hidden_units, dense_units=1, \n",
    "                                  input_shape=(time_steps,1), activation='tanh')\n",
    "model_LSTM_with_attention.summary()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "826/826 - 7s - loss: 0.0014 - 7s/epoch - 8ms/step\n",
      "Epoch 2/30\n",
      "826/826 - 3s - loss: 0.0014 - 3s/epoch - 4ms/step\n",
      "Epoch 3/30\n",
      "826/826 - 3s - loss: 0.0014 - 3s/epoch - 4ms/step\n",
      "Epoch 4/30\n",
      "826/826 - 3s - loss: 0.0014 - 3s/epoch - 4ms/step\n",
      "Epoch 5/30\n",
      "826/826 - 3s - loss: 0.0014 - 3s/epoch - 4ms/step\n",
      "Epoch 6/30\n",
      "826/826 - 3s - loss: 0.0014 - 3s/epoch - 4ms/step\n",
      "Epoch 7/30\n",
      "826/826 - 3s - loss: 0.0014 - 3s/epoch - 4ms/step\n",
      "Epoch 8/30\n",
      "826/826 - 3s - loss: 0.0014 - 3s/epoch - 4ms/step\n",
      "Epoch 9/30\n",
      "826/826 - 3s - loss: 0.0014 - 3s/epoch - 4ms/step\n",
      "Epoch 10/30\n",
      "826/826 - 3s - loss: 0.0014 - 3s/epoch - 4ms/step\n",
      "Epoch 11/30\n",
      "826/826 - 3s - loss: 0.0014 - 3s/epoch - 4ms/step\n",
      "Epoch 12/30\n",
      "826/826 - 3s - loss: 0.0013 - 3s/epoch - 4ms/step\n",
      "Epoch 13/30\n",
      "826/826 - 4s - loss: 0.0013 - 4s/epoch - 4ms/step\n",
      "Epoch 14/30\n",
      "826/826 - 3s - loss: 0.0013 - 3s/epoch - 4ms/step\n",
      "Epoch 15/30\n",
      "826/826 - 3s - loss: 0.0013 - 3s/epoch - 4ms/step\n",
      "Epoch 16/30\n",
      "826/826 - 3s - loss: 0.0012 - 3s/epoch - 4ms/step\n",
      "Epoch 17/30\n",
      "826/826 - 3s - loss: 0.0012 - 3s/epoch - 4ms/step\n",
      "Epoch 18/30\n",
      "826/826 - 4s - loss: 0.0012 - 4s/epoch - 4ms/step\n",
      "Epoch 19/30\n",
      "826/826 - 4s - loss: 0.0011 - 4s/epoch - 4ms/step\n",
      "Epoch 20/30\n",
      "826/826 - 3s - loss: 0.0011 - 3s/epoch - 4ms/step\n",
      "Epoch 21/30\n",
      "826/826 - 3s - loss: 0.0010 - 3s/epoch - 4ms/step\n",
      "Epoch 22/30\n",
      "826/826 - 3s - loss: 9.7438e-04 - 3s/epoch - 4ms/step\n",
      "Epoch 23/30\n",
      "826/826 - 3s - loss: 9.1555e-04 - 3s/epoch - 4ms/step\n",
      "Epoch 24/30\n",
      "826/826 - 4s - loss: 8.4324e-04 - 4s/epoch - 4ms/step\n",
      "Epoch 25/30\n",
      "826/826 - 3s - loss: 7.9183e-04 - 3s/epoch - 4ms/step\n",
      "Epoch 26/30\n",
      "826/826 - 3s - loss: 7.0189e-04 - 3s/epoch - 4ms/step\n",
      "Epoch 27/30\n",
      "826/826 - 3s - loss: 6.4809e-04 - 3s/epoch - 4ms/step\n",
      "Epoch 28/30\n",
      "826/826 - 4s - loss: 5.7369e-04 - 4s/epoch - 4ms/step\n",
      "Epoch 29/30\n",
      "826/826 - 3s - loss: 5.4151e-04 - 3s/epoch - 4ms/step\n",
      "Epoch 30/30\n",
      "826/826 - 3s - loss: 4.8911e-04 - 3s/epoch - 4ms/step\n",
      "26/26 [==============================] - 1s 3ms/step - loss: 3.8727e-04\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.0809e-04\n",
      "Train set MSE = 0.0003873\n",
      "Test set MSE = 0.0003081\n"
     ]
    }
   ],
   "source": [
    "model_LSTM_with_attention.fit(trainX, trainY, epochs=epochs, batch_size=1, verbose=2)\n",
    "\n",
    "# Evalute model\n",
    "train_mse = model_LSTM_with_attention.evaluate(trainX, trainY)\n",
    "test_mse = model_LSTM_with_attention.evaluate(testX, testY)\n",
    "\n",
    "# Print error\n",
    "print(f\"Train set MSE = {train_mse:.{7}f}\")\n",
    "print(f\"Test set MSE = {test_mse:.{7}f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Train_set_MSE</th>\n",
       "      <th>Test_set_MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simple RNN</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simple RNN with Attention</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>0.000813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSTM_with_attention</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.000308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model  Train_set_MSE  Test_set_MSE\n",
       "0                 Simple RNN       0.000065      0.000029\n",
       "0  Simple RNN with Attention       0.000929      0.000813\n",
       "0                       LSTM       0.000031      0.000010\n",
       "0        LSTM_with_attention       0.000387      0.000308"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance = pd.concat([performance, pd.DataFrame({'model':'LSTM_with_attention','Train_set_MSE':train_mse,'Test_set_MSE':test_mse},index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-Directional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 20, 1)]           0         \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 20, 4)             64        \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 20, 1)             5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69 (276.00 Byte)\n",
      "Trainable params: 69 (276.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_BiLSTM(hidden_units, dense_units, input_shape, activation):\n",
    "    x=Input(shape=input_shape)\n",
    "    BiLSTM_layer = Bidirectional(LSTM(hidden_units, return_sequences=True, activation=activation))(x)\n",
    "    #attention_layer = attention()(LSTM_layer)\n",
    "    outputs=Dense(dense_units, trainable=True, activation=activation)(BiLSTM_layer)\n",
    "    model=Model(x,outputs)\n",
    "    model.compile(loss='mse', optimizer='adam')    \n",
    "    return model    \n",
    "\n",
    "# Create the model , train and evaluate\n",
    "model_BiLSTM = create_BiLSTM(hidden_units=hidden_units, dense_units=1, \n",
    "                                  input_shape=(time_steps,1), activation='tanh')\n",
    "model_BiLSTM.summary()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "826/826 - 10s - loss: 0.0014 - 10s/epoch - 12ms/step\n",
      "Epoch 2/30\n",
      "826/826 - 4s - loss: 0.0014 - 4s/epoch - 5ms/step\n",
      "Epoch 3/30\n",
      "826/826 - 3s - loss: 0.0014 - 3s/epoch - 4ms/step\n",
      "Epoch 4/30\n",
      "826/826 - 4s - loss: 0.0014 - 4s/epoch - 4ms/step\n",
      "Epoch 5/30\n",
      "826/826 - 3s - loss: 0.0014 - 3s/epoch - 4ms/step\n",
      "Epoch 6/30\n",
      "826/826 - 3s - loss: 0.0014 - 3s/epoch - 4ms/step\n",
      "Epoch 7/30\n",
      "826/826 - 3s - loss: 0.0013 - 3s/epoch - 4ms/step\n",
      "Epoch 8/30\n",
      "826/826 - 4s - loss: 0.0013 - 4s/epoch - 5ms/step\n",
      "Epoch 9/30\n",
      "826/826 - 4s - loss: 0.0013 - 4s/epoch - 5ms/step\n",
      "Epoch 10/30\n",
      "826/826 - 4s - loss: 0.0013 - 4s/epoch - 5ms/step\n",
      "Epoch 11/30\n",
      "826/826 - 4s - loss: 0.0013 - 4s/epoch - 5ms/step\n",
      "Epoch 12/30\n",
      "826/826 - 4s - loss: 0.0012 - 4s/epoch - 4ms/step\n",
      "Epoch 13/30\n",
      "826/826 - 4s - loss: 0.0012 - 4s/epoch - 4ms/step\n",
      "Epoch 14/30\n",
      "826/826 - 4s - loss: 0.0011 - 4s/epoch - 5ms/step\n",
      "Epoch 15/30\n",
      "826/826 - 4s - loss: 0.0010 - 4s/epoch - 5ms/step\n",
      "Epoch 16/30\n",
      "826/826 - 3s - loss: 8.3156e-04 - 3s/epoch - 4ms/step\n",
      "Epoch 17/30\n",
      "826/826 - 3s - loss: 7.3951e-04 - 3s/epoch - 4ms/step\n",
      "Epoch 18/30\n",
      "826/826 - 4s - loss: 4.7591e-04 - 4s/epoch - 5ms/step\n",
      "Epoch 19/30\n",
      "826/826 - 3s - loss: 2.7522e-04 - 3s/epoch - 4ms/step\n",
      "Epoch 20/30\n",
      "826/826 - 4s - loss: 1.8709e-04 - 4s/epoch - 4ms/step\n",
      "Epoch 21/30\n",
      "826/826 - 4s - loss: 1.5448e-04 - 4s/epoch - 4ms/step\n",
      "Epoch 22/30\n",
      "826/826 - 4s - loss: 1.5633e-04 - 4s/epoch - 4ms/step\n",
      "Epoch 23/30\n",
      "826/826 - 4s - loss: 1.3949e-04 - 4s/epoch - 4ms/step\n",
      "Epoch 24/30\n",
      "826/826 - 3s - loss: 1.3943e-04 - 3s/epoch - 4ms/step\n",
      "Epoch 25/30\n",
      "826/826 - 4s - loss: 1.1539e-04 - 4s/epoch - 5ms/step\n",
      "Epoch 26/30\n",
      "826/826 - 3s - loss: 1.1468e-04 - 3s/epoch - 4ms/step\n",
      "Epoch 27/30\n",
      "826/826 - 3s - loss: 8.9343e-05 - 3s/epoch - 4ms/step\n",
      "Epoch 28/30\n",
      "826/826 - 3s - loss: 1.1245e-04 - 3s/epoch - 4ms/step\n",
      "Epoch 29/30\n",
      "826/826 - 4s - loss: 9.0626e-05 - 4s/epoch - 4ms/step\n",
      "Epoch 30/30\n",
      "826/826 - 4s - loss: 8.0558e-05 - 4s/epoch - 4ms/step\n",
      "26/26 [==============================] - 2s 2ms/step - loss: 0.0023\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0023\n",
      "Train set MSE = 0.0022669\n",
      "Test set MSE = 0.0023458\n"
     ]
    }
   ],
   "source": [
    "model_BiLSTM.fit(trainX, trainY, epochs=epochs, batch_size=1, verbose=2)\n",
    "\n",
    "# Evalute model\n",
    "train_mse = model_BiLSTM.evaluate(trainX, trainY)\n",
    "test_mse = model_BiLSTM.evaluate(testX, testY)\n",
    "\n",
    "# Print error\n",
    "print(f\"Train set MSE = {train_mse:.{7}f}\")\n",
    "print(f\"Test set MSE = {test_mse:.{7}f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Train_set_MSE</th>\n",
       "      <th>Test_set_MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simple RNN</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simple RNN with Attention</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>0.000813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSTM_with_attention</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.000308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bi-LSTM</td>\n",
       "      <td>0.002267</td>\n",
       "      <td>0.002346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model  Train_set_MSE  Test_set_MSE\n",
       "0                 Simple RNN       0.000065      0.000029\n",
       "0  Simple RNN with Attention       0.000929      0.000813\n",
       "0                       LSTM       0.000031      0.000010\n",
       "0        LSTM_with_attention       0.000387      0.000308\n",
       "0                    Bi-LSTM       0.002267      0.002346"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance = pd.concat([performance, pd.DataFrame({'model':'Bi-LSTM','Train_set_MSE':train_mse,'Test_set_MSE':test_mse},index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-Directional With Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 20, 1)]           0         \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 20, 4)             64        \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 20, 1)             5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69 (276.00 Byte)\n",
      "Trainable params: 69 (276.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_BiLSTM_with_attention(hidden_units, dense_units, input_shape, activation):\n",
    "    x=Input(shape=input_shape)\n",
    "    BiLSTM_layer = Bidirectional(LSTM(hidden_units, return_sequences=True, activation=activation))(x)\n",
    "    attention_layer = attention()(BiLSTM_layer)\n",
    "    outputs=Dense(dense_units, trainable=True, activation=activation)(BiLSTM_layer)\n",
    "    model=Model(x,outputs)\n",
    "    model.compile(loss='mse', optimizer='adam')    \n",
    "    return model    \n",
    "\n",
    "# Create the model with attention, train and evaluate\n",
    "model_BiLSTM_with_attention = create_BiLSTM_with_attention(hidden_units=hidden_units, dense_units=1, \n",
    "                                  input_shape=(time_steps,1), activation='tanh')\n",
    "model_BiLSTM_with_attention.summary()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "826/826 - 10s - loss: 0.0016 - 10s/epoch - 12ms/step\n",
      "Epoch 2/30\n",
      "826/826 - 3s - loss: 0.0015 - 3s/epoch - 4ms/step\n",
      "Epoch 3/30\n",
      "826/826 - 3s - loss: 0.0015 - 3s/epoch - 4ms/step\n",
      "Epoch 4/30\n",
      "826/826 - 4s - loss: 0.0015 - 4s/epoch - 5ms/step\n",
      "Epoch 5/30\n",
      "826/826 - 3s - loss: 0.0015 - 3s/epoch - 4ms/step\n",
      "Epoch 6/30\n",
      "826/826 - 3s - loss: 0.0015 - 3s/epoch - 4ms/step\n",
      "Epoch 7/30\n",
      "826/826 - 4s - loss: 0.0014 - 4s/epoch - 4ms/step\n",
      "Epoch 8/30\n",
      "826/826 - 4s - loss: 0.0015 - 4s/epoch - 5ms/step\n",
      "Epoch 9/30\n",
      "826/826 - 4s - loss: 0.0014 - 4s/epoch - 4ms/step\n",
      "Epoch 10/30\n",
      "826/826 - 4s - loss: 0.0014 - 4s/epoch - 5ms/step\n",
      "Epoch 11/30\n",
      "826/826 - 4s - loss: 0.0014 - 4s/epoch - 5ms/step\n",
      "Epoch 12/30\n",
      "826/826 - 4s - loss: 0.0014 - 4s/epoch - 5ms/step\n",
      "Epoch 13/30\n",
      "826/826 - 3s - loss: 0.0014 - 3s/epoch - 4ms/step\n",
      "Epoch 14/30\n",
      "826/826 - 3s - loss: 0.0014 - 3s/epoch - 4ms/step\n",
      "Epoch 15/30\n",
      "826/826 - 4s - loss: 0.0014 - 4s/epoch - 5ms/step\n",
      "Epoch 16/30\n",
      "826/826 - 4s - loss: 0.0014 - 4s/epoch - 4ms/step\n",
      "Epoch 17/30\n",
      "826/826 - 4s - loss: 0.0013 - 4s/epoch - 5ms/step\n",
      "Epoch 18/30\n",
      "826/826 - 4s - loss: 0.0013 - 4s/epoch - 4ms/step\n",
      "Epoch 19/30\n",
      "826/826 - 4s - loss: 0.0013 - 4s/epoch - 4ms/step\n",
      "Epoch 20/30\n",
      "826/826 - 4s - loss: 0.0013 - 4s/epoch - 5ms/step\n",
      "Epoch 21/30\n",
      "826/826 - 4s - loss: 0.0013 - 4s/epoch - 5ms/step\n",
      "Epoch 22/30\n",
      "826/826 - 3s - loss: 0.0013 - 3s/epoch - 4ms/step\n",
      "Epoch 23/30\n",
      "826/826 - 4s - loss: 0.0013 - 4s/epoch - 4ms/step\n",
      "Epoch 24/30\n",
      "826/826 - 3s - loss: 0.0013 - 3s/epoch - 4ms/step\n",
      "Epoch 25/30\n",
      "826/826 - 3s - loss: 0.0012 - 3s/epoch - 4ms/step\n",
      "Epoch 26/30\n",
      "826/826 - 3s - loss: 0.0012 - 3s/epoch - 4ms/step\n",
      "Epoch 27/30\n",
      "826/826 - 3s - loss: 0.0012 - 3s/epoch - 4ms/step\n",
      "Epoch 28/30\n",
      "826/826 - 3s - loss: 0.0012 - 3s/epoch - 4ms/step\n",
      "Epoch 29/30\n",
      "826/826 - 3s - loss: 0.0011 - 3s/epoch - 4ms/step\n",
      "Epoch 30/30\n",
      "826/826 - 4s - loss: 0.0011 - 4s/epoch - 5ms/step\n",
      "26/26 [==============================] - 1s 3ms/step - loss: 0.0015\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Train set MSE = 0.0015162\n",
      "Test set MSE = 0.0013637\n"
     ]
    }
   ],
   "source": [
    "model_BiLSTM_with_attention.fit(trainX, trainY, epochs=epochs, batch_size=1, verbose=2)\n",
    "\n",
    "# Evalute model\n",
    "train_mse = model_BiLSTM_with_attention.evaluate(trainX, trainY)\n",
    "test_mse = model_BiLSTM_with_attention.evaluate(testX, testY)\n",
    "\n",
    "# Print error\n",
    "print(f\"Train set MSE = {train_mse:.{7}f}\")\n",
    "print(f\"Test set MSE = {test_mse:.{7}f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Train_set_MSE</th>\n",
       "      <th>Test_set_MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simple RNN</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simple RNN with Attention</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>0.000813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSTM_with_attention</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.000308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bi-LSTM</td>\n",
       "      <td>0.002267</td>\n",
       "      <td>0.002346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bi-LSTM_with_attention</td>\n",
       "      <td>0.001516</td>\n",
       "      <td>0.001364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model  Train_set_MSE  Test_set_MSE\n",
       "0                 Simple RNN       0.000065      0.000029\n",
       "0  Simple RNN with Attention       0.000929      0.000813\n",
       "0                       LSTM       0.000031      0.000010\n",
       "0        LSTM_with_attention       0.000387      0.000308\n",
       "0                    Bi-LSTM       0.002267      0.002346\n",
       "0     Bi-LSTM_with_attention       0.001516      0.001364"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance = pd.concat([performance, pd.DataFrame({'model':'Bi-LSTM_with_attention','Train_set_MSE':train_mse,'Test_set_MSE':test_mse},index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Train_set_MSE</th>\n",
       "      <th>Test_set_MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simple RNN</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSTM_with_attention</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.000308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simple RNN with Attention</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>0.000813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bi-LSTM_with_attention</td>\n",
       "      <td>0.001516</td>\n",
       "      <td>0.001364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bi-LSTM</td>\n",
       "      <td>0.002267</td>\n",
       "      <td>0.002346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model  Train_set_MSE  Test_set_MSE\n",
       "0                       LSTM       0.000031      0.000010\n",
       "0                 Simple RNN       0.000065      0.000029\n",
       "0        LSTM_with_attention       0.000387      0.000308\n",
       "0  Simple RNN with Attention       0.000929      0.000813\n",
       "0     Bi-LSTM_with_attention       0.001516      0.001364\n",
       "0                    Bi-LSTM       0.002267      0.002346"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance.sort_values(by=['Train_set_MSE','Test_set_MSE'], ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After comparing the MSE scores of all the Models LSTM model is the one with least MSE scores so it is better to choose this model. \n",
    "- Due to the complexity of the attention models secure higher MSE scores.\n",
    "- There isnt much difference between train and test accuracies so there is no overfitting in the models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DEV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
