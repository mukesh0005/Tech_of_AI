{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DdRekMxEZjF"
      },
      "source": [
        "# 1. Download the IMDB dataset\n",
        "\n",
        "Download the data from http://ai.stanford.edu/~amaas/data/sentiment/ or http://s3.amazonaws.com/text-datasets/aclImdb.zip\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FrUvgPwEZjH"
      },
      "source": [
        "# 2. Processing the Training and test Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qm9SSebfEZjH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "imdb_dir = './data/aclImdb'\n",
        "train_dir = os.path.join(imdb_dir, 'train')\n",
        "labels_train = []\n",
        "texts_train = []\n",
        "for label_type in ['pos', 'neg']:\n",
        "    dir_name = os.path.join(train_dir, label_type)\n",
        "    for fname in os.listdir(dir_name):\n",
        "        if fname[-4:] == '.txt':\n",
        "            f = open(os.path.join(dir_name, fname))\n",
        "            texts_train.append(f.read())\n",
        "            f.close()\n",
        "            if label_type == 'neg':\n",
        "                labels_train.append(0)\n",
        "            else:\n",
        "                labels_train.append(1)\n",
        "\n",
        "# Load Test Data\n",
        "imdb_dir = './data/aclImdb'\n",
        "test_dir = os.path.join(imdb_dir, 'test')\n",
        "labels_test = []\n",
        "texts_test = []\n",
        "for label_type in ['pos', 'neg']:\n",
        "    dir_name = os.path.join(test_dir, label_type)\n",
        "    for fname in os.listdir(dir_name):\n",
        "        if fname[-4:] == '.txt':\n",
        "            f = open(os.path.join(dir_name, fname))\n",
        "            texts_test.append(f.read())\n",
        "            f.close()\n",
        "            if label_type == 'neg':\n",
        "                labels_test.append(0)\n",
        "            else:\n",
        "                labels_test.append(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "old2_hp9EZjI",
        "outputId": "92b31964-cd26-41df-f271-9730dc9722fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 88582 unique tokens.\n",
            "Shape of data tensor: (25000, 100)\n",
            "Shape of label tensor: (25000,)\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy\n",
        "\n",
        "maxlen = 100\n",
        "training_samples = 200\n",
        "validation_samples = 5000\n",
        "max_words = 10000\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(texts_train)\n",
        "sequences = tokenizer.texts_to_sequences(texts_train)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "data = pad_sequences(sequences, maxlen=maxlen)\n",
        "labels = numpy.asarray(labels_train)\n",
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of label tensor:', labels.shape)\n",
        "\n",
        "indices = numpy.arange(data.shape[0])\n",
        "indices = numpy.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "\n",
        "x_train = data[:training_samples]\n",
        "y_train = labels[:training_samples]\n",
        "x_val = data[training_samples: training_samples + validation_samples]\n",
        "y_val = labels[training_samples: training_samples + validation_samples]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BA-ph7IFEZjJ",
        "outputId": "bf276de7-3b19-4447-ae0e-cc2fd0f77921"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 25000, 100)\n",
            "(0, 25000, 100)\n"
          ]
        }
      ],
      "source": [
        "print(x_train.shape)\n",
        "print(x_val.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skU1vIQ5EZjJ"
      },
      "source": [
        "# 3. Load Glove"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06U3Uxg0EZjJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy\n",
        "\n",
        "glove_dir = './Glove'\n",
        "embeddings_index = {}\n",
        "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'))\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = numpy.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jEb4y0EEZjK"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 100\n",
        "\n",
        "embedding_matrix = numpy.zeros((max_words, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    if i < max_words:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDgijIbUEZjK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
